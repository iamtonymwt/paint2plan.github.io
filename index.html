<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Paint2Plan: Image Painting Enables Imitation Learning with VLMs">
  <meta name="keywords" content="Visual Language Model, Imitation Learning, Painting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Paint2Plan: Image Painting Enables Imitation Learning with VLMs</title>

  <!-- Thumbnail for social media sharing -->
  <meta property="og:image" content="media/thumbnail.png">

  <!-- Favicon -->
  <link rel="icon" href="media/thumbnail.png" type="image/jpeg">

  <script>
    window.dataLayer = window.dataLayer || [];
  </script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="./static/source_serif_4.css">
  <link rel="stylesheet" href="./static/source_sans_3.css">  
  <link rel="stylesheet" href="./static/academicons.min.css">
  <link rel="stylesheet" href="./static/fontawesome/css/fontawesome.css">
  <link rel="stylesheet" href="./static/fontawesome/css/brands.css">
  <link rel="stylesheet" href="./static/fontawesome/css/light.css">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body onload="updateInTheWild();updateBimanual();">

<section class="hero">
  <div class="hero-body">
    <div class="container is-fullhd">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Paint2Plan: Image Painting Enables Imitation Learning with VLMs</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://iamtonymwt.github.io/">Wentao Ma</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://github.com/kwonathan">Teyun Kwon</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://profiles.imperial.ac.uk/e.johns">Edward Johns</a><sup>1,3</sup>,
            </span>
          </div>
          <div class="is-size-5 affiliation">
            <sup>1</sup>Imperial College London,
            <sup>2</sup>University of Oxford,
            <sup>3</sup>The Robot Learning Lab at Imperial College London,
          </div>
          <br>
          <div class="affiliation-note">
            <sup>*</sup> Corresponding Author
          </div>
          <div class="button-container">
            <!-- <a href="./rekep.pdf" target="_blank" class="button"><i class="fa-light fa-file"></i>&emsp14;PDF</a>
            <a href="http://arxiv.org/abs/2409.01652" target="_blank" class="button"><i class="ai ai-arxiv"></i>&emsp14;arXiv</a>
            <a href="https://youtu.be/2S8YhBdLdww" target="_blank" class="button"><i class="fa-light fa-film"></i>&emsp14;Video</a>
            <a href="https://x.com/wenlong_huang/status/1829135436717142319" target="_blank" class="button"><i class="fa-brands fa-x-twitter"></i>&emsp14;tl;dr</a>
            <a href="https://github.com/huangwl18/ReKep" target="_blank" class="button"><i class="fa-light fa-code"></i>&emsp14;Code</a> -->
            <a href="" target="_blank" class="button"><i class="fa-light fa-file"></i>&emsp14;PDF</a>
            <a href="" target="_blank" class="button"><i class="ai ai-arxiv"></i>&emsp14;arXiv</a>
            <a href="" target="_blank" class="button"><i class="fa-light fa-film"></i>&emsp14;Video</a>
            <a href="" target="_blank" class="button"><i class="fa-light fa-code"></i>&emsp14;Code</a>
        </div>
        </div>
      </div>
    </div>
  </div>
</section>


<div class="container is-four-fifths">
<div class="columns is-centered has-text-centered">
  <div class="column is-five-fifths">
    <hr class="rounded">
    <div class="rows">
      <img src="media/figures/figure1.jpg" class="method-image" />
      <p class="content has-text-justified">We introduce novel image painting techniques for our VLM-based trajectory prediction method that only requires a few (less than 10) demonstrations. The painted images enable VLMs to understand the scene, learn multimodal patterns, and replan trajectories if failure is detected.</b>
      </p>
    </div> 
  </div>
</div>
</div>

  

<div class="container is-max-widescreen">
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        We show that by painting coordinate frames and trajectory lines onto images, a single pre-trained Vision Language Model (VLM) can perform few-shot imitation learning without any additional modules. Our method, Paint2Plan, uses a painted image as input and directly outputs the trajectory of the end-effector in 6 DoF, and undergoes replanning if necessary. By designing and integrating our image painting techniques in the perception, planning, and replanning phases, Paint2Plan enables robust performance in low-data regimes by enhancing the VLMs' multimodal pattern-learning ability. Through extensive simulation and physical experiments, we show that Paint2Plan achieves on-par or superior performance on a variety of everyday tasks, and a detailed ablation study confirms the effectiveness of our image painting techniques. This insight underscores the potential for future applications of VLMs to be used as single backbones in diverse and complex robotics tasks.
      </p>
    </div>
  </div>
</div>



<hr class="rounded">
<div class="rows">
  <h2 class="title is-3">Method</h2>
  <img src="media/figures/main_pipeline.jpg" class="method-image" />
  <p class="content has-text-justified">Overview of the Paint2Plan pipeline. First, demonstrations are prepared by painting the images and processing the trajectory. Second, given these demonstrations and a new painted input image, the VLM predicts an initial trajectory. Finally, the generated trajectory is painted, and replanned if deemed unsatisfactory.
  </p>
</div>


<hr class="rounded">
<div class="rows">
  <h2 class="title is-3">Quantitative Results</h2>
  <p class="content has-text-justified">Please see our paper for full results, but the figures below summarise some of our experiments.
  </p>

  <img src="media/figures/main_exp.png" is-3 class="method-image" width="80%" />
  <p class="content has-text-justified">We introduce 8 simulation tasks(shown bellow) to represent a range of real-world robot manipulation tasks. We benchmark the performance of Paint2Plan against two state-of-the-art methods, namely Keypoint Action Tokens(KAT), and Diffusion Policy(DP). We show the success rates with 10 demonstrations for each task, for Paint2Plan, KAT with action tokens (act.), KAT with Cartesian positions and Euler angles (ang.) and Diffusion Policy.
  </p>
  
  <div class="columns">
    <div class="column has-text-centered">
      <img src="media/figures/number_demo.jpg" class="method-image" />
      <p class="content has-text-justified">Success rates for the baselines and our method with varying numbers of demonstrations.</p>
    </div>
  
    <div class="column has-text-centered">
      <img src="media/figures/keywaypoints_number.jpg" class="method-image" />
      <p class="content has-text-justified">Success rates of our method under six varying numbers of key waypoints: none, extremely-less, less, equal, more, extremely-more, all compared to the number of objects in the scene.</p>
    </div>
  </div>

  <img src="media/figures/VLM.png" class="method-image" />
  <p class="content has-text-justified">Success rates of different VLMs for the inference and critic phases.
  </p>
</div>


<hr class="rounded">
<div class="rows">
  <h2 class="title is-3">Video of Simulation Tasks</h2>

  <p class="content has-text-justified">
  We now illustrate how Paint2Plan can solve robotics tasks in a simulation environment. The testing environment is built on Pybullet, using a Franka Emika Panda robot. We use Gemini 1.5 Pro for inference, and Claude 3.5 Sonnet for the critic. For each task, we provide 10 demonstrations and replan for 1 iteration.
  </p>

  <div class="columns is-multiline">
    <div class="column is-half has-text-centered">
      <video id="s1" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/fork_scoop_can.mov" type="video/mp4">
      </video>
      <p class="title is-5">Fork Scoop Can</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s2" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/mug_box_cubes.mov" type="video/mp4">
      </video>
      <p class="title is-5">Mug Box Cubes</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s3" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/mug_on_box.mov" type="video/mp4">
      </video>
      <p class="title is-5">Mug On Box</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s4" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/mug_on_fork.mov" type="video/mp4">
      </video>
      <p class="title is-5">Mug On Fork</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s5" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/mug_pour_box.mov" type="video/mp4">
      </video>
      <p class="title is-5">Mug Pour Box</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s6" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/sponge_wipe_cubes.mov" type="video/mp4">
      </video>
      <p class="title is-5">Sponge Wipe Cubes</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s7" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/sponge_wipe_mug.mov" type="video/mp4">
      </video>
      <p class="title is-5">Sponge Wipe Mug</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="s8" controls autoplay loop muted width="80%">
        <source src="media/simu_videos/upright_fork.mov" type="video/mp4">
      </video>
      <p class="title is-5">Upright Fork</p>
    </div>
  </div>
</div>


<hr class="rounded">
<div class="rows">
  <h2 class="title is-3">Video of Real World Tasks</h2>

  <p class="content has-text-justified">
  We conduct real-world experiments with a Kinova 'MICO2' robot on 4 tasks, and each with two variants (with and without distractors), totalling 8 cases. We provide 10 demonstrations and replan for 1 iteration.
  </p>

  <div class="columns is-multiline">
    <div class="column is-half has-text-centered">
      <video id="r1" loop muted width="100%">
        <source src="media/real_videos/sponge_on_box_clear.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Sponge On Box(w/o)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r2" controls autoplay loop muted width="100%">
        <source src="media/real_videos/sponge_on_box_obs.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Sponge On Box(w/)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r3" controls autoplay loop muted width="100%">
        <source src="media/real_videos/sponge_on_sponge_clear.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Sponge On Sponge(w/o)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r4" controls autoplay loop muted width="100%">
        <source src="media/real_videos/sponge_on_sponge_obs.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Sponge On Sponge(w/)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r5" controls autoplay loop muted width="100%">
        <source src="media/real_videos/stirring_clear_1.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Stirring(w/o)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r6" controls autoplay loop muted width="100%">
        <source src="media/real_videos/stirring_obs_1.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Stirring(w/)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r7" controls autoplay loop muted width="100%">
        <source src="media/real_videos/toast_clear.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Toast(w/o)</p>
    </div>

    <div class="column is-half has-text-centered">
      <video id="r8" controls autoplay loop muted width="100%">
        <source src="media/real_videos/toast_obs.MOV" type="video/mp4">
      </video>
      <p class="title is-5">Toast(w/)</p>
    </div>
  </div>
</div>



<hr class="rounded">
<h2 class="title is-3">Acknowledgments</h2>
<p>
  Special thanks to Norman Di Palo and Georgios Papagiannis for their discussions and suggestions during the work.
</p>
<!-- <hr class="rounded">
<h2 class="title is-3">BibTeX</h2>
<p class="bibtex">
    @article{huang2024rekep, <br>
    &nbsp;&nbsp;title = {ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation}, <br>
    &nbsp;&nbsp;author = {Huang, Wenlong and Wang, Chen and Li, Yunzhu and Zhang, Ruohan and Fei-Fei, Li}, <br>
    &nbsp;&nbsp;journal = {arXiv preprint arXiv:2409.01652}, <br>
    &nbsp;&nbsp;year = {2024} <br>
    }
</p> -->

</section>
</div>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from <a href="https://rekep-robot.github.io/">ReKep</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
